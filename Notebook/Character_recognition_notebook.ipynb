{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468b3843-3514-45bb-8f4e-ea69efd55e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================================================================\n",
    "# Handwritten Character Recognition using Convolutional Neural Network (CNN)\n",
    "# ==========================================================================================\n",
    "# Description:\n",
    "# This project implements a CNN-based approach to recognize handwritten English characters \n",
    "# (A-Z). It leverages a labeled dataset of grayscale images, where each image corresponds \n",
    "# to an uppercase English alphabet. The goal is to accurately classify each character using \n",
    "# deep learning techniques with PyTorch.\n",
    "# =========================================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0748534-aa0e-4a0f-b5ab-7138786f6b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Required Libraries\n",
    "\n",
    "# Data manipulation and visualization\n",
    "import numpy as np                          # Numerical computations\n",
    "import pandas as pd                         # Data handling and preprocessing\n",
    "import matplotlib.pyplot as plt             # Basic plotting\n",
    "import seaborn as sns                       # Advanced visualization\n",
    "\n",
    "# PyTorch - Deep Learning Framework\n",
    "import torch                                # Core PyTorch module\n",
    "import torch.nn as nn                       # Neural network components\n",
    "import torch.nn.functional as F             # Functional API for layers and activations\n",
    "from torch.utils.data import Dataset, DataLoader  # Custom dataset handling and batching\n",
    "\n",
    "# Scikit-learn - Model evaluation and splitting\n",
    "from sklearn.model_selection import train_test_split  # Splitting dataset\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay  # Evaluation\n",
    "\n",
    "# Progress bar utility\n",
    "from tqdm.auto import tqdm                  # For displaying training progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ccf585-3823-48f5-8872-84bd0f36a538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for GPU Availability\n",
    "\n",
    "# Let's check if a GPU is available for faster training; otherwise, we'll use the CPU.\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Printing the device that will be used for training\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e09bb5-ad95-439b-af6d-25e7d45bc96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the Dataset\n",
    "\n",
    "# Load the handwritten character dataset (make sure the path is correct for your setup)\n",
    "data = pd.read_csv('path/to/your/dataset')\n",
    "\n",
    "# Display the shape of the dataset to get an idea of how many samples and features we have\n",
    "print(\"Shape of the dataset:\", data.shape)\n",
    "\n",
    "# Display the first few rows to quickly inspect the structure and format\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e422cd-beb0-4b45-9196-81081ead62a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the Distribution of Character Labels\n",
    "\n",
    "# Plotting the count of each character label (0 represents 'A', 25 represents 'Z')\n",
    "plt.figure(figsize=(12, 4))\n",
    "sns.countplot(x=data['0'], palette=\"crest\")\n",
    "\n",
    "# Adding meaningful titles and axis labels\n",
    "plt.title(\"Distribution of Character Labels (0 = A, 25 = Z)\")\n",
    "plt.xlabel(\"Character Label\")\n",
    "plt.ylabel(\"Number of Samples\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85286b92-d459-45ab-a5cd-ac2d4db5189d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Separating Features and Labels + Normalizing Input Images\n",
    "\n",
    "# Split the dataset into features (X) and labels (y)\n",
    "X = data.drop('0', axis=1).values / 255.0  # Normalize pixel values to [0, 1]\n",
    "y = data['0'].values                       # Labels (0 = A, 25 = Z)\n",
    "\n",
    "# Reshape X to match CNN input shape: (samples, channels, height, width)\n",
    "X = X.reshape(-1, 1, 28, 28).astype(np.float32)\n",
    "\n",
    "# Sanity check\n",
    "print(f\"Feature shape: {X.shape}, Label shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684889fd-1176-43a8-bc7e-5779e885cb06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Train-Test Split with Stratified Sampling\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "# Stratify ensures that the distribution of character classes remains balanced in both sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2,       # Use 20% of the data for testing\n",
    "    stratify=y,          # Preserve label distribution\n",
    "    random_state=42      # For reproducibility\n",
    ")\n",
    "\n",
    "# Display the number of samples in each set\n",
    "print(f\"Number of training samples: {len(X_train)}\")\n",
    "print(f\"Number of testing samples: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da44f790-9f98-4e92-9188-baffd9e54d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Define Custom Dataset for Character Recognition\n",
    "\n",
    "class CharacterDataset(Dataset):\n",
    "    # Custom PyTorch Dataset for loading character images and labels.\n",
    "    # Each image is expected to be a 28x28 grayscale image, normalized and reshaped.\n",
    "    \n",
    "    def __init__(self, images, labels):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        # Return total number of samples\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Fetch the image and label at the given index and convert them to tensors\n",
    "        image = torch.tensor(self.images[idx], dtype=torch.float32)\n",
    "        label = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06923ed-73c1-4c94-a374-a2b72f333649",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Create Dataset and DataLoader Instances\n",
    "\n",
    "# Wrap the training and testing data into PyTorch Dataset objects\n",
    "train_dataset = CharacterDataset(X_train, y_train)\n",
    "test_dataset = CharacterDataset(X_test, y_test)\n",
    "\n",
    "# Create DataLoader objects for batching and shuffling\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)   # Shuffle for training\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)    # No shuffle for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf5a13c-e484-4e90-8359-822429967ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Define the Convolutional Neural Network (CNN) Architecture\n",
    "\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNModel, self).__init__()\n",
    "\n",
    "        # First convolutional layer: 1 input channel -> 32 output channels\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1)\n",
    "\n",
    "        # Second convolutional layer: 32 input channels -> 64 output channels\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "\n",
    "        # Max pooling layer with kernel size 2x2\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # Dropout for regularization\n",
    "        self.dropout = nn.Dropout(p=0.25)\n",
    "\n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(in_features=64 * 7 * 7, out_features=256)\n",
    "        self.fc2 = nn.Linear(in_features=256, out_features=26)  # Output: 26 classes (A-Z)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply convolution -> ReLU -> pooling\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "\n",
    "        # Apply dropout\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        # Flatten the tensor for the fully connected layers\n",
    "        x = x.view(-1, 64 * 7 * 7)\n",
    "\n",
    "        # Fully connected layers with ReLU and dropout\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "# Instantiate the model and move it to the configured device (CPU or GPU)\n",
    "model = CNNModel().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499b6afd-982d-4b0f-9df1-264d3e3e552c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Define the Loss Function and Optimizer\n",
    "\n",
    "# CrossEntropyLoss is suitable for multi-class classification problems\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Adam optimizer with a learning rate of 0.001 (commonly a good starting point)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f968abd-6015-4bca-9b2b-c83fd2eff083",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Training Loop with Accuracy and Loss Tracking\n",
    "\n",
    "# Lists to store training loss and accuracy after each epoch\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "\n",
    "def train_model(epochs):\n",
    "    \n",
    "    # Trains the CNN model for a given number of epochs and logs progress with tqdm.\n",
    "    model.train()  # Set the model to training mode\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        # tqdm loop for real-time progress bar\n",
    "        loop = tqdm(train_loader, leave=False)\n",
    "\n",
    "        for inputs, labels in loop:\n",
    "            inputs = inputs.to(device).float()      # Move inputs to GPU and ensure float dtype\n",
    "            labels = labels.to(device).long()       # Move labels to GPU and ensure long dtype\n",
    "\n",
    "            optimizer.zero_grad()                   # Clear previous gradients\n",
    "            outputs = model(inputs)                 # Forward pass\n",
    "            loss = criterion(outputs, labels)       # Compute loss\n",
    "            loss.backward()                         # Backward pass\n",
    "            optimizer.step()                        # Update weights\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            # Calculate accuracy\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "            # Update tqdm progress bar\n",
    "            loop.set_description(f\"Epoch [{epoch+1}/{epochs}]\")\n",
    "            loop.set_postfix(loss=loss.item(), acc=100 * correct / total)\n",
    "\n",
    "        # Calculate average loss and accuracy for the epoch\n",
    "        epoch_loss = running_loss\n",
    "        epoch_acc = 100 * correct / total\n",
    "        train_losses.append(epoch_loss)\n",
    "        train_accuracies.append(epoch_acc)\n",
    "\n",
    "        # Print summary after each epoch\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}] - Loss: {epoch_loss:.4f} - Accuracy: {epoch_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1597927-2888-491e-92d3-15357dc84904",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8: Start Training the CNN Model\n",
    "\n",
    "# Begin training for 20 epochs\n",
    "train_model(epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6af8f2d-7e9a-4048-87be-a96bb19b9ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 9: Evaluate Model Performance on Test Set\n",
    "\n",
    "# Switch model to evaluation mode (disables dropout, etc.)\n",
    "model.eval()\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "# Disable gradient computation for evaluation (improves speed & reduces memory usage)\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs = inputs.to(device).float()\n",
    "        labels = labels.to(device).long()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Get predicted class with highest score\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "        # Save predictions and actual labels for further evaluation\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Print overall test accuracy\n",
    "print(f\"âœ… Test Accuracy: {100 * correct / total:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80ca816-3ffd-4c8e-a5fb-a33ce37cc797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 10: Define Class Labels\n",
    "\n",
    "# Generate a list of uppercase English alphabets ['A', 'B', ..., 'Z']\n",
    "classes = [chr(i) for i in range(ord('A'), ord('Z') + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7fbfc5d-70b8-4ab3-be77-7dbf592fd4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 11: Confusion Matrix Visualization\n",
    "\n",
    "# Compute the confusion matrix\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "# Plot the confusion matrix as a heatmap\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=classes, yticklabels=classes)\n",
    "\n",
    "# Set plot labels and title\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix of Handwritten Character Predictions')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdccb49f-fc11-4b5b-856f-576b70cc0c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 12: Classification Report\n",
    "\n",
    "# Display precision, recall, f1-score and support for each class\n",
    "print(\"Classification Report:\\n\")\n",
    "print(classification_report(all_labels, all_preds, target_names=classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3222a0-5a98-4dbe-aa3d-4765eff7cf39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 13: Training Performance Visualization - Loss & Accuracy Curves\n",
    "\n",
    "# Plot the Training Loss Curve\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(range(1, len(train_losses) + 1), train_losses, label='Training Loss', color='red')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss Curve')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot the Training Accuracy Curve\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(range(1, len(train_accuracies) + 1), train_accuracies, label='Training Accuracy', color='green')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Training Accuracy Curve')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a4b485-9ffb-4ede-a25a-ae872fffc00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 14: Visualizing Model Predictions on Test Samples\n",
    "\n",
    "def imshow(img):\n",
    "\n",
    "    # Utility function to display a single grayscale image.\n",
    "    img = img.squeeze().numpy()  # Remove channel dimension and convert to numpy\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.axis('off')\n",
    "\n",
    "# Fetch a batch of test images\n",
    "dataiter = iter(test_loader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# Move data to the appropriate device\n",
    "images = images.to(device).float()\n",
    "labels = labels.to(device)\n",
    "\n",
    "# Get model predictions\n",
    "outputs = model(images)\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "# Plot first 10 images with predicted vs actual labels\n",
    "plt.figure(figsize=(15, 4))\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i + 1)\n",
    "    imshow(images[i].cpu())\n",
    "    plt.title(f\"True: {classes[labels[i]]}\\nPred: {classes[predicted[i]]}\")\n",
    "plt.suptitle(\"Model Predictions on Sample Test Images\", fontsize=14)\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.93])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2875e8-3ec3-4b9d-a024-22c594c08d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 15: Visualizing the Normalized Confusion Matrix\n",
    "\n",
    "# Normalize the confusion matrix by row (true labels)\n",
    "cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "# Create and plot the normalized confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm_norm, display_labels=classes)\n",
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "disp.plot(cmap='Blues', ax=ax, values_format=\".2f\")\n",
    "plt.title(\"Normalized Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87f041c-e26a-438e-b799-2694a529a777",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 16: Visualizing Misclassified Characters\n",
    "\n",
    "# Identify indices where the predicted label does not match the true label\n",
    "wrong_indices = [i for i in range(len(all_preds)) if all_preds[i] != all_labels[i]]\n",
    "\n",
    "# Plot the first 10 misclassified images\n",
    "plt.figure(figsize=(15, 6))\n",
    "for i, idx in enumerate(wrong_indices[:10]):\n",
    "    img = X_test[idx].squeeze()  # Remove channel dimension\n",
    "    plt.subplot(2, 5, i + 1)\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.title(f\"True: {classes[y_test[idx]]}\\nPred: {classes[all_preds[idx]]}\")\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.suptitle(\"Examples of Misclassified Characters\", fontsize=14)\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.93])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34cffd10-e7ea-448d-a07d-14f0880e95fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 17: Visualizing Per-Class Accuracy\n",
    "\n",
    "# Extract diagonal (true positives) and compute per-class accuracy\n",
    "cm_diag = np.diag(cm)                         # Correct predictions per class\n",
    "class_accuracy = cm_diag / cm.sum(axis=1)    # Accuracy = TP / Total actual for each class\n",
    "\n",
    "# Plotting per-class accuracy\n",
    "plt.figure(figsize=(12, 4))\n",
    "sns.barplot(x=classes, y=class_accuracy * 100, palette=\"viridis\")\n",
    "plt.title(\"Per-Class Accuracy (%)\", fontsize=14)\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Character\")\n",
    "plt.ylim(0, 100)\n",
    "plt.grid(True, axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78275f16-fa2d-4d3b-a708-640ba6d77146",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 18: Save the Trained Model\n",
    "\n",
    "# Save the model's learned parameters to a .pt file\n",
    "model_save_path = \"path/to/save/model\"\n",
    "torch.save(model.state_dict(), model_save_path)\n",
    "\n",
    "print(f\"Model saved successfully at:\\n{model_save_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (torchenv)",
   "language": "python",
   "name": "torchenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
